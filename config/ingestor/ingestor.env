# Ingestor Service Configuration
# ================================
# Infrastructure params (DATABASE_URL, NATS_URL, MINIO endpoint/credentials,
# QDRANT host/port, EMBEDDER host/port) are set via docker-compose
# environment from central .env

# Service Settings
INGESTOR_ENABLED=true
INGESTOR_HEALTH_PORT=8080

# Database
INGESTOR_DATABASE_ECHO=false

# NATS (stream/consumer names are service-specific)
INGESTOR_NATS_STREAM_NAME=ECHOMIND
INGESTOR_NATS_CONSUMER_NAME=ingestor-consumer

# MinIO (bucket name is service-specific)
INGESTOR_MINIO_SECURE=false
INGESTOR_MINIO_BUCKET=echomind-documents

# Qdrant
# INGESTOR_QDRANT_API_KEY=  # Uncomment if Qdrant requires authentication

# Embedder gRPC
# TODO: Revert to 30.0 once embedder runs on GPU
INGESTOR_EMBEDDER_TIMEOUT=600

# nv-ingest Extraction Settings
# Extraction method: pdfium (fast), pdfium_hybrid, nemotron_parse (requires NIM)
INGESTOR_EXTRACT_METHOD=pdfium

# Text extraction granularity: 'document' (full doc) or 'page' (per-page chunks)
# NVIDIA research: 'page' achieves highest accuracy (0.648) with lowest variance
INGESTOR_TEXT_DEPTH=page

# Chunking Settings (in TOKENS, not characters)
# NVIDIA recommends: 512-1024 tokens, 10-20% overlap (optimal: 15% = 154 tokens for 1024 size)
# ⚠️ OVERLAP RATIONALE: 124 tokens = 12.1% (user specified)
#    - Within acceptable 10-20% range per NVIDIA research
#    - Balances context preservation vs storage overhead
#    - Consider increasing to 154 (15%) if retrieval quality issues arise
INGESTOR_CHUNK_SIZE=1024
INGESTOR_CHUNK_OVERLAP=124

# Tokenizer for chunking (HuggingFace model)
# MUST match your embedding model for perfect tokenization alignment
# nvidia/llama-nemotron-embed-1b-v2 is the SAME model as your embedder
INGESTOR_TOKENIZER=nvidia/llama-nemotron-embed-1b-v2

# HuggingFace access token (REQUIRED for gated models like nvidia/llama-nemotron)
# Get token at: https://huggingface.co/settings/tokens
# Accept license at: https://huggingface.co/nvidia/llama-nemotron-embed-1b-v2
INGESTOR_HF_ACCESS_TOKEN=

# Optional NIMs (set to true if NIMs are deployed)
# YOLOX: Table and chart detection
INGESTOR_YOLOX_ENABLED=false
INGESTOR_YOLOX_ENDPOINT=http://yolox-nim:8000

# Riva: Audio transcription
INGESTOR_RIVA_ENABLED=false
INGESTOR_RIVA_ENDPOINT=riva:50051

# Retry Settings
INGESTOR_MAX_RETRIES=3
INGESTOR_RETRY_BASE_DELAY=1.0

# Logging
INGESTOR_LOG_LEVEL=INFO
